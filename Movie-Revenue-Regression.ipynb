{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS 310 Project 2\n",
    "### Authors: Sean Rendar & Jess Strait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import useful packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "import xgboost as xgb\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_log_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in training and testing data\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'belongs_to_collection', 'budget', 'genres', 'homepage', 'imdb_id', 'original_language', 'original_title', 'overview', 'popularity', 'poster_path', 'production_companies', 'production_countries', 'release_date', 'runtime', 'spoken_languages', 'status', 'tagline', 'title', 'Keywords', 'cast', 'crew', 'revenue']\n",
      "id                         int64\n",
      "belongs_to_collection     object\n",
      "budget                     int64\n",
      "genres                    object\n",
      "homepage                  object\n",
      "imdb_id                   object\n",
      "original_language         object\n",
      "original_title            object\n",
      "overview                  object\n",
      "popularity               float64\n",
      "poster_path               object\n",
      "production_companies      object\n",
      "production_countries      object\n",
      "release_date              object\n",
      "runtime                  float64\n",
      "spoken_languages          object\n",
      "status                    object\n",
      "tagline                   object\n",
      "title                     object\n",
      "Keywords                  object\n",
      "cast                      object\n",
      "crew                      object\n",
      "revenue                    int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(list(train.columns))\n",
    "print(train.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                              belongs_to_collection    budget  \\\n",
      "0   1  [{'id': 313576, 'name': 'Hot Tub Time Machine ...  14000000   \n",
      "1   2  [{'id': 107674, 'name': 'The Princess Diaries ...  40000000   \n",
      "2   3                                                NaN   3300000   \n",
      "3   4                                                NaN   1200000   \n",
      "4   5                                                NaN         0   \n",
      "\n",
      "                                              genres  \\\n",
      "0                     [{'id': 35, 'name': 'Comedy'}]   \n",
      "1  [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...   \n",
      "2                      [{'id': 18, 'name': 'Drama'}]   \n",
      "3  [{'id': 53, 'name': 'Thriller'}, {'id': 18, 'n...   \n",
      "4  [{'id': 28, 'name': 'Action'}, {'id': 53, 'nam...   \n",
      "\n",
      "                            homepage    imdb_id original_language  \\\n",
      "0                                NaN  tt2637294                en   \n",
      "1                                NaN  tt0368933                en   \n",
      "2  http://sonyclassics.com/whiplash/  tt2582802                en   \n",
      "3         http://kahaanithefilm.com/  tt1821480                hi   \n",
      "4                                NaN  tt1380152                ko   \n",
      "\n",
      "                             original_title  \\\n",
      "0                    Hot Tub Time Machine 2   \n",
      "1  The Princess Diaries 2: Royal Engagement   \n",
      "2                                  Whiplash   \n",
      "3                                   Kahaani   \n",
      "4                                      마린보이   \n",
      "\n",
      "                                            overview  popularity  ... runtime  \\\n",
      "0  When Lou, who has become the \"father of the In...    6.575393  ...    93.0   \n",
      "1  Mia Thermopolis is now a college graduate and ...    8.248895  ...   113.0   \n",
      "2  Under the direction of a ruthless instructor, ...   64.299990  ...   105.0   \n",
      "3  Vidya Bagchi (Vidya Balan) arrives in Kolkata ...    3.174936  ...   122.0   \n",
      "4  Marine Boy is the story of a former national s...    1.148070  ...   118.0   \n",
      "\n",
      "                                    spoken_languages    status  \\\n",
      "0           [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
      "1           [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
      "2           [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
      "3  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...  Released   \n",
      "4           [{'iso_639_1': 'ko', 'name': '한국어/조선말'}]  Released   \n",
      "\n",
      "                                             tagline  \\\n",
      "0  The Laws of Space and Time are About to be Vio...   \n",
      "1  It can take a lifetime to find true love; she'...   \n",
      "2    The road to greatness can take you to the edge.   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                                      title  \\\n",
      "0                    Hot Tub Time Machine 2   \n",
      "1  The Princess Diaries 2: Royal Engagement   \n",
      "2                                  Whiplash   \n",
      "3                                   Kahaani   \n",
      "4                                Marine Boy   \n",
      "\n",
      "                                            Keywords  \\\n",
      "0  [{'id': 4379, 'name': 'time travel'}, {'id': 9...   \n",
      "1  [{'id': 2505, 'name': 'coronation'}, {'id': 42...   \n",
      "2  [{'id': 1416, 'name': 'jazz'}, {'id': 1523, 'n...   \n",
      "3  [{'id': 10092, 'name': 'mystery'}, {'id': 1054...   \n",
      "4                                                NaN   \n",
      "\n",
      "                                                cast  \\\n",
      "0  [{'cast_id': 4, 'character': 'Lou', 'credit_id...   \n",
      "1  [{'cast_id': 1, 'character': 'Mia Thermopolis'...   \n",
      "2  [{'cast_id': 5, 'character': 'Andrew Neimann',...   \n",
      "3  [{'cast_id': 1, 'character': 'Vidya Bagchi', '...   \n",
      "4  [{'cast_id': 3, 'character': 'Chun-soo', 'cred...   \n",
      "\n",
      "                                                crew     revenue tt  \n",
      "0  [{'credit_id': '59ac067c92514107af02c8c8', 'de...  12314651.0  0  \n",
      "1  [{'credit_id': '52fe43fe9251416c7502563d', 'de...  95149435.0  0  \n",
      "2  [{'credit_id': '54d5356ec3a3683ba0000039', 'de...  13092000.0  0  \n",
      "3  [{'credit_id': '52fe48779251416c9108d6eb', 'de...  16000000.0  0  \n",
      "4  [{'credit_id': '52fe464b9251416c75073b43', 'de...   3923970.0  0  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# Combine train and test for feature engineering\n",
    "# 0 = train, 1 = test\n",
    "train['tt'] = 0\n",
    "test['tt'] = 1\n",
    "data = train.append(test)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6351\n"
     ]
    }
   ],
   "source": [
    "# Create some binary variables for variables of interest to be made numeric\n",
    "# Was the original language English?\n",
    "data['original_language'] = data.original_language.fillna(\"\")\n",
    "data['orig_eng'] = data.original_language.apply(lambda x: 1 if x == 'en' else 0)\n",
    "data['orig_chin'] = data.original_language.apply(lambda x: 1 if x == 'zh' else 0)\n",
    "data['orig_french'] = data.original_language.apply(lambda x: 1 if x == 'fr' else 0)\n",
    "data['orig_it'] = data.original_language.apply(lambda x: 1 if x == 'it' else 0)\n",
    "data['orig_hindi'] = data.original_language.apply(lambda x: 1 if x == 'hi' else 0)\n",
    "\n",
    "print(sum(data.orig_eng))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5617\n"
     ]
    }
   ],
   "source": [
    "# Was the movie produced in the US?\n",
    "data['production_countries'] = data.production_countries.fillna(\"\")\n",
    "data['production_countries'] = data.production_countries.apply(lambda x: re.findall(\"'name': \\'(.+?)\\'\", x))\n",
    "data['usa_prod'] = data.production_countries.apply(lambda x: 1 if 'United States of America' in x else 0)\n",
    "print(sum(data.usa_prod))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'belongs_to_collection', 'budget', 'genres', 'homepage',\n",
      "       'imdb_id', 'original_language', 'original_title', 'overview',\n",
      "       'popularity', 'poster_path', 'production_companies',\n",
      "       'production_countries', 'release_date', 'runtime', 'spoken_languages',\n",
      "       'status', 'tagline', 'title', 'Keywords', 'cast', 'crew', 'revenue',\n",
      "       'tt', 'orig_eng', 'orig_chin', 'orig_french', 'orig_it', 'orig_hindi',\n",
      "       'usa_prod', 'Action', 'Adventure', 'Animation', 'Comedy', 'Crime',\n",
      "       'Documentary', 'Drama', 'Family', 'Fantasy', 'Foreign', 'History',\n",
      "       'Horror', 'Music', 'Mystery', 'Romance', 'Science Fiction', 'TV Movie',\n",
      "       'Thriller', 'War', 'Western'],\n",
      "      dtype='object')\n",
      "1084\n"
     ]
    }
   ],
   "source": [
    "# What was the movie genre?\n",
    "data['genres'] = data['genres'].fillna('')\n",
    "data['genres'] = data['genres'].apply(lambda x:re.findall(\"'name': \\'(.+?)\\'\", x))\n",
    "genre_dummies = data['genres'].str.join('|').str.get_dummies()\n",
    "genre_dummies['id'] = data['id']\n",
    "data = data.merge(genre_dummies, on='id')\n",
    "print(data.columns)\n",
    "print(sum(data['Crime']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1481\n"
     ]
    }
   ],
   "source": [
    "# Is the movie part of a collection?\n",
    "data['belongs_to_collection'] = data['belongs_to_collection'].fillna('')\n",
    "data['film_collect'] = data.belongs_to_collection.apply(lambda x: 0 if x=='' else 1)\n",
    "print(sum(data.film_collect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    }
   ],
   "source": [
    "# Can we text mine for some popular collections?\n",
    "data['franchise'] = data.belongs_to_collection.apply(lambda x: 1 if re.search(\"(?:Star Wars|Rocky|Harry Potter|Lord of the Rings|Star Trek|Hobbit|Twilight|Pirates of the Caribbean|Hunger Games|Jurassic Park)\", x) else 0)\n",
    "data['superhero'] = data.belongs_to_collection.apply(lambda x: 1 if re.search(\"(?:Avengers|X-Men|Batman|Spider-Man|Iron Man|Transformers)\", x) else 0)\n",
    "data['action_fran'] = data.belongs_to_collection.apply(lambda x: 1 if re.search(\"(?:James Bond|Rambo|Fast and Furious|Mission: Impossible|Bourne|Indiana Jones)\", x) else 0)\n",
    "print(sum(data.franchise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6465\n"
     ]
    }
   ],
   "source": [
    "# Was English part of the spoken language?\n",
    "data['spoken_languages'] = data.spoken_languages.fillna(\"\")\n",
    "data['speak_eng'] = data.spoken_languages.apply(lambda x: 1 if 'en' in x else 0)\n",
    "print(sum(data.speak_eng))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264\n"
     ]
    }
   ],
   "source": [
    "# Can we text mine for some famous actors?\n",
    "data['cast'] = data.cast.fillna(\"\")\n",
    "data['famous_actor'] = data.cast.apply(lambda x: 1 if re.search(\"(?:Dwayne Johnson|Tom Hanks|Brad Pitt|Morgan Freeman|Clint Eastwood|Matt Damon)\", x) else 0)\n",
    "# Create special feature for action stars, as we know action films tend to gross higher\n",
    "data['famous_action_act'] = data.cast.apply(lambda x: 1 if re.search(\"(?:Sylvester Stallone|Harrison Ford|Robert Downey|Hugh Jackman|Bruce Willis|Tom Cruise)\", x) else 0)\n",
    "# Create special features for actors more frequently occurring in high-grossing movies\n",
    "data['samuel_l'] = data.cast.apply(lambda x: 1 if \"Samuel L. Jackson\" in x else 0)\n",
    "data['will_s'] = data.cast.apply(lambda x: 1 if \"Will Smith\" in x else 0)\n",
    "data['leo'] = data.cast.apply(lambda x: 1 if \"Leonardo DiCaprio\" in x else 0)\n",
    "data['depp'] = data.cast.apply(lambda x: 1 if \"Johnny Depp\" in x else 0)\n",
    "data['freeman'] = data.cast.apply(lambda x: 1 if \"Morgan Freeman\" in x else 0)\n",
    "data['deniro'] = data.cast.apply(lambda x: 1 if \"Robert De Niro\" in x else 0)\n",
    "print(sum(data.famous_actor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285\n"
     ]
    }
   ],
   "source": [
    "# Can we text mine for famous actresses?\n",
    "data['famous_actress'] = data.cast.apply(lambda x: 1 if re.search(\"(?:Meryl Streep|Jennifer Lawrence|Anne Hathaway|Emma Watson|Sandra Bullock|Halle Berry|Scarlett Johansson|Julia Roberts|Jennifer Aniston|Nicole Kidman)\", x) else 0)\n",
    "print(sum(data.famous_actress))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213\n"
     ]
    }
   ],
   "source": [
    "# Can we text mine for some famous directors?\n",
    "data['crew'] = data.crew.fillna(\"\")\n",
    "data['famous_director'] = data.crew.apply(lambda x: 1 if re.search(\"(?:Steven Spielberg|Martin Scorsese|Quentin Tarantino|Stanley Kubrick|Tim Burton|Christopher Nolan|James Cameron|David Fincher|Robert Zemeckis)\", x) else 0)\n",
    "print(sum(data.famous_director))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2122\n"
     ]
    }
   ],
   "source": [
    "# Can we text mine for some popular production companies?\n",
    "data['production_companies'] = data.production_companies.fillna(\"\")\n",
    "data['famous_prod'] = data.production_companies.apply(lambda x: 1 if re.search(\"(?:Disney|Warner Bros|Paramount|MGM|Twentieth Century Fox|Universal Pictures)\", x) else 0)\n",
    "print(sum(data.famous_prod))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1481\n"
     ]
    }
   ],
   "source": [
    "# Does the movie have a tagline?\n",
    "data['tagline'] = data['tagline'].fillna(\"\")\n",
    "data['tag_present'] = data.belongs_to_collection.apply(lambda x: 0 if x=='' else 1)\n",
    "print(sum(data.tag_present))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6984\n"
     ]
    }
   ],
   "source": [
    "# Does the movie have a production company?\n",
    "data['production_companies'] = data['production_companies'].fillna(\"\")\n",
    "data['prod_present'] = data.production_companies.apply(lambda x: 0 if x=='' else 1)\n",
    "print(sum(data.prod_present))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2366\n"
     ]
    }
   ],
   "source": [
    "# Does the movie have a homepage?\n",
    "data['homepage'] = data['homepage'].fillna(\"\")\n",
    "data['home_present'] = data.homepage.apply(lambda x: 0 if x=='' else 1)\n",
    "print(sum(data.home_present))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7.398000e+03\n",
       "mean     2.264167e+07\n",
       "std      3.695113e+07\n",
       "min      0.000000e+00\n",
       "25%      0.000000e+00\n",
       "50%      8.000000e+06\n",
       "75%      2.875000e+07\n",
       "max      3.800000e+08\n",
       "Name: budget, dtype: float64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.budget.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720\n",
      "2643\n"
     ]
    }
   ],
   "source": [
    "# What was the movie budget?\n",
    "data['budget'] = data['budget'].fillna(data.budget.mean())\n",
    "\n",
    "# Was the movie budget greater than the average $65 million\n",
    "data['big_budget'] = data.budget.apply(lambda x:1 if x>65000000 else 0)\n",
    "print(sum(data.big_budget))\n",
    "\n",
    "# Was the movie budget extra small?\n",
    "data['small_budget'] = data.budget.apply(lambda x:1 if x<2000000 else 0)\n",
    "print(sum(data.small_budget))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664\n"
     ]
    }
   ],
   "source": [
    "# How long was the runtime?\n",
    "data['runtime'] = data['runtime'].fillna(114)\n",
    "data['runtime'] = pd.to_numeric(data['runtime'])\n",
    "data['longer_than_two_fifteen'] = data.runtime.apply(lambda x: 1 if x>135 else 0)\n",
    "print(sum(data.longer_than_two_fifteen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mine the release date\n",
    "data['release_date'] = data['release_date'].fillna('')\n",
    "data['month'] = pd.DatetimeIndex(data['release_date']).month\n",
    "data['year'] = pd.DatetimeIndex(data['release_date']).year\n",
    "data['weekday'] = pd.DatetimeIndex(data['release_date']).dayofweek\n",
    "\n",
    "# Create summer dummies\n",
    "data['summer'] = data.month.apply(lambda x: 1 if 5<x<9 else 0)\n",
    "\n",
    "# Create dummies for some decades\n",
    "data['before_1980'] = data.year.apply(lambda x: 1 if x<1980 else 0)\n",
    "data['before_y2k'] = data.year.apply(lambda x: 1 if 1979<x<2000 else 0)\n",
    "data['before_2010'] = data.year.apply(lambda x: 1 if 1999<x<2010 else 0)\n",
    "data['since_2010'] = data.year.apply(lambda x: 1 if 2011<x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "457\n"
     ]
    }
   ],
   "source": [
    "# Mining for keywords that could influence revenue\n",
    "data['Keywords'] = data['Keywords'].fillna('')\n",
    "data['woman_director'] = data.Keywords.apply(lambda x: 1 if \"woman director\" in x else 0)\n",
    "data['independent_film'] = data.Keywords.apply(lambda x: 1 if \"independent film\" in x else 0)\n",
    "data['base_novel'] = data.Keywords.apply(lambda x: 1 if \"based on novel\" in x else 0)\n",
    "data['sequel'] = data.Keywords.apply(lambda x: 1 if \"sequel\" in x else 0)\n",
    "data['credits'] = data.Keywords.apply(lambda x: 1 if \"duringcreditsstinger\" in x else 0)\n",
    "\n",
    "print(data.woman_director.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "847\n"
     ]
    }
   ],
   "source": [
    "# See if title has changed from the original title\n",
    "data['original_title'] = data.original_title.fillna('')\n",
    "data['title'] = data.title.fillna('')\n",
    "data['title_change']= np.where(data['title'] == data['original_title'], 0, 1)\n",
    "print(data['title_change'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up remaining NAs\n",
    "data['popularity'] = data.popularity.fillna(\"\")\n",
    "data['revenue'] = data.revenue.fillna(\"\")\n",
    "data['popularity'] = data['popularity'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit data frame to variables of interest\n",
    "num_data = data[['id', 'budget', 'popularity','orig_eng', 'usa_prod', 'tt', 'franchise', 'Action', 'Adventure', 'Animation',\n",
    "       'Comedy', 'Crime', 'Documentary', 'Drama', 'Family', 'Fantasy', 'tag_present', 'home_present', 'famous_action_act', 'will_s', 'samuel_l', 'leo', 'depp', 'freeman',\n",
    "       'Foreign', 'History', 'Horror', 'Music', 'Mystery', 'Romance', 'prod_present', 'superhero', 'action_fran',\n",
    "       'Science Fiction', 'TV Movie', 'Thriller', 'War', 'Western', 'film_collect', 'speak_eng', 'famous_actor', 'famous_actress','famous_director', 'famous_prod', 'revenue',\n",
    "                'big_budget', 'longer_than_two_fifteen', 'month', 'year', 'summer', 'weekday', 'before_y2k', 'before_2010', 'since_2010', 'runtime',\n",
    "                'woman_director', 'independent_film', 'base_novel', 'sequel', 'credits', 'title_change', 'deniro']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>budget</th>\n",
       "      <th>popularity</th>\n",
       "      <th>orig_eng</th>\n",
       "      <th>usa_prod</th>\n",
       "      <th>franchise</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>...</th>\n",
       "      <th>before_2010</th>\n",
       "      <th>since_2010</th>\n",
       "      <th>runtime</th>\n",
       "      <th>woman_director</th>\n",
       "      <th>independent_film</th>\n",
       "      <th>base_novel</th>\n",
       "      <th>sequel</th>\n",
       "      <th>credits</th>\n",
       "      <th>title_change</th>\n",
       "      <th>deniro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  budget  popularity  orig_eng  usa_prod  franchise  Action  \\\n",
       "0     True    True        True      True      True       True    True   \n",
       "1     True    True        True      True      True       True    True   \n",
       "2     True    True        True      True      True       True    True   \n",
       "3     True    True        True      True      True       True    True   \n",
       "4     True    True        True      True      True       True    True   \n",
       "...    ...     ...         ...       ...       ...        ...     ...   \n",
       "2995  True    True        True      True      True       True    True   \n",
       "2996  True    True        True      True      True       True    True   \n",
       "2997  True    True        True      True      True       True    True   \n",
       "2998  True    True        True      True      True       True    True   \n",
       "2999  True    True        True      True      True       True    True   \n",
       "\n",
       "      Adventure  Animation  Comedy  ...  before_2010  since_2010  runtime  \\\n",
       "0          True       True    True  ...         True        True     True   \n",
       "1          True       True    True  ...         True        True     True   \n",
       "2          True       True    True  ...         True        True     True   \n",
       "3          True       True    True  ...         True        True     True   \n",
       "4          True       True    True  ...         True        True     True   \n",
       "...         ...        ...     ...  ...          ...         ...      ...   \n",
       "2995       True       True    True  ...         True        True     True   \n",
       "2996       True       True    True  ...         True        True     True   \n",
       "2997       True       True    True  ...         True        True     True   \n",
       "2998       True       True    True  ...         True        True     True   \n",
       "2999       True       True    True  ...         True        True     True   \n",
       "\n",
       "      woman_director  independent_film  base_novel  sequel  credits  \\\n",
       "0               True              True        True    True     True   \n",
       "1               True              True        True    True     True   \n",
       "2               True              True        True    True     True   \n",
       "3               True              True        True    True     True   \n",
       "4               True              True        True    True     True   \n",
       "...              ...               ...         ...     ...      ...   \n",
       "2995            True              True        True    True     True   \n",
       "2996            True              True        True    True     True   \n",
       "2997            True              True        True    True     True   \n",
       "2998            True              True        True    True     True   \n",
       "2999            True              True        True    True     True   \n",
       "\n",
       "      title_change  deniro  \n",
       "0             True    True  \n",
       "1             True    True  \n",
       "2             True    True  \n",
       "3             True    True  \n",
       "4             True    True  \n",
       "...            ...     ...  \n",
       "2995          True    True  \n",
       "2996          True    True  \n",
       "2997          True    True  \n",
       "2998          True    True  \n",
       "2999          True    True  \n",
       "\n",
       "[3000 rows x 61 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split back into training and testing\n",
    "train = num_data.loc[num_data['tt'] == 0]\n",
    "test = num_data.loc[num_data['tt'] == 1]\n",
    "# Clean data\n",
    "train = train.drop('tt', 1)\n",
    "test = test.drop('tt', 1)\n",
    "train['revenue'] = train['revenue'].astype('int64')\n",
    "train.applymap(np.isreal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for modeling \n",
    "x_train = train.loc[:,train.columns!='revenue']\n",
    "x_train = x_train.drop('id', 1)\n",
    "y_train = train['revenue']\n",
    "x_test = test.loc[:,test.columns!='revenue']\n",
    "x_test = x_test.drop('id', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "x_train = x_train.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x)))\n",
    "x_test = x_test.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "budget                     0\n",
       "popularity                 0\n",
       "orig_eng                   0\n",
       "usa_prod                   0\n",
       "franchise                  0\n",
       "Action                     0\n",
       "Adventure                  0\n",
       "Animation                  0\n",
       "Comedy                     0\n",
       "Crime                      0\n",
       "Documentary                0\n",
       "Drama                      0\n",
       "Family                     0\n",
       "Fantasy                    0\n",
       "tag_present                0\n",
       "home_present               0\n",
       "famous_action_act          0\n",
       "will_s                     0\n",
       "samuel_l                   0\n",
       "leo                        0\n",
       "depp                       0\n",
       "freeman                    0\n",
       "Foreign                    0\n",
       "History                    0\n",
       "Horror                     0\n",
       "Music                      0\n",
       "Mystery                    0\n",
       "Romance                    0\n",
       "prod_present               0\n",
       "superhero                  0\n",
       "action_fran                0\n",
       "Science Fiction            0\n",
       "TV Movie                   0\n",
       "Thriller                   0\n",
       "War                        0\n",
       "Western                    0\n",
       "film_collect               0\n",
       "speak_eng                  0\n",
       "famous_actor               0\n",
       "famous_actress             0\n",
       "famous_director            0\n",
       "famous_prod                0\n",
       "big_budget                 0\n",
       "longer_than_two_fifteen    0\n",
       "month                      0\n",
       "year                       0\n",
       "summer                     0\n",
       "weekday                    0\n",
       "before_y2k                 0\n",
       "before_2010                0\n",
       "since_2010                 0\n",
       "runtime                    0\n",
       "woman_director             0\n",
       "independent_film           0\n",
       "base_novel                 0\n",
       "sequel                     0\n",
       "credits                    0\n",
       "title_change               0\n",
       "deniro                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "budget                     0\n",
       "popularity                 0\n",
       "orig_eng                   0\n",
       "usa_prod                   0\n",
       "franchise                  0\n",
       "Action                     0\n",
       "Adventure                  0\n",
       "Animation                  0\n",
       "Comedy                     0\n",
       "Crime                      0\n",
       "Documentary                0\n",
       "Drama                      0\n",
       "Family                     0\n",
       "Fantasy                    0\n",
       "tag_present                0\n",
       "home_present               0\n",
       "famous_action_act          0\n",
       "will_s                     0\n",
       "samuel_l                   0\n",
       "leo                        0\n",
       "depp                       0\n",
       "freeman                    0\n",
       "Foreign                    0\n",
       "History                    0\n",
       "Horror                     0\n",
       "Music                      0\n",
       "Mystery                    0\n",
       "Romance                    0\n",
       "prod_present               0\n",
       "superhero                  0\n",
       "action_fran                0\n",
       "Science Fiction            0\n",
       "TV Movie                   0\n",
       "Thriller                   0\n",
       "War                        0\n",
       "Western                    0\n",
       "film_collect               0\n",
       "speak_eng                  0\n",
       "famous_actor               0\n",
       "famous_actress             0\n",
       "famous_director            0\n",
       "famous_prod                0\n",
       "big_budget                 0\n",
       "longer_than_two_fifteen    0\n",
       "month                      0\n",
       "year                       0\n",
       "summer                     0\n",
       "weekday                    0\n",
       "before_y2k                 0\n",
       "before_2010                0\n",
       "since_2010                 0\n",
       "runtime                    0\n",
       "woman_director             0\n",
       "independent_film           0\n",
       "base_novel                 0\n",
       "sequel                     0\n",
       "credits                    0\n",
       "title_change               0\n",
       "deniro                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill possible NAs in test set\n",
    "x_test['TV Movie'] = x_test['TV Movie'].fillna(0)\n",
    "x_test['month'] = x_test['month'].fillna(0)\n",
    "x_test['year'] = x_test['year'].fillna(0)\n",
    "x_test['weekday'] = x_test['weekday'].fillna(0)\n",
    "x_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start with decision tree classifier\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with decision tree classifier\n",
    "y_pred = model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50673078  5000000 17530973 ...   777423    74918   182857]\n"
     ]
    }
   ],
   "source": [
    "# Baseline 1 RMSLE: 2.5\n",
    "test_pred = model.predict(x_test)\n",
    "print(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First submission RMSLE: 2.94175"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parameter grid for RandomForest cross-validation\n",
    "param = { 'max_depth': [5, 10, 15, 20, 25, None],\n",
    " 'max_features': ['auto', 'sqrt'],\n",
    " 'min_samples_leaf': [1, 2, 4],\n",
    " 'min_samples_split': [2, 5, 10],\n",
    " 'n_estimators': [10, 25, 50, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:    3.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=4, error_score=nan,\n",
       "                   estimator=RandomForestRegressor(bootstrap=True,\n",
       "                                                   ccp_alpha=0.0,\n",
       "                                                   criterion='mse',\n",
       "                                                   max_depth=None,\n",
       "                                                   max_features='auto',\n",
       "                                                   max_leaf_nodes=None,\n",
       "                                                   max_samples=None,\n",
       "                                                   min_impurity_decrease=0.0,\n",
       "                                                   min_impurity_split=None,\n",
       "                                                   min_samples_leaf=1,\n",
       "                                                   min_samples_split=2,\n",
       "                                                   min_weight_fraction_leaf=0.0,\n",
       "                                                   n_estimators=100,\n",
       "                                                   n_jobs=None, oob_score=False,\n",
       "                                                   random_state=None, verbose=0,\n",
       "                                                   warm_start=False),\n",
       "                   iid='deprecated', n_iter=4, n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [5, 10, 15, 20, 25, None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [10, 25, 50, 100]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=True, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random forest model identified with RandomizedSearchCV\n",
    "forest = RandomForestRegressor()\n",
    "rf_random = RandomizedSearchCV(estimator = forest, param_distributions = param, n_iter = 4, cv = 4, verbose=2, random_state=42, n_jobs = -1, return_train_score = True)\n",
    "\n",
    "rf_random.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.240231</td>\n",
       "      <td>0.003902</td>\n",
       "      <td>0.012484</td>\n",
       "      <td>0.001115</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20</td>\n",
       "      <td>{'n_estimators': 50, 'min_samples_split': 5, '...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.704604</td>\n",
       "      <td>0.702167</td>\n",
       "      <td>0.035749</td>\n",
       "      <td>1</td>\n",
       "      <td>0.866996</td>\n",
       "      <td>0.861138</td>\n",
       "      <td>0.863663</td>\n",
       "      <td>0.864847</td>\n",
       "      <td>0.864161</td>\n",
       "      <td>0.002115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.576629</td>\n",
       "      <td>0.008529</td>\n",
       "      <td>0.010501</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>{'n_estimators': 50, 'min_samples_split': 5, '...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.694651</td>\n",
       "      <td>0.701833</td>\n",
       "      <td>0.020514</td>\n",
       "      <td>2</td>\n",
       "      <td>0.853191</td>\n",
       "      <td>0.863521</td>\n",
       "      <td>0.855475</td>\n",
       "      <td>0.862032</td>\n",
       "      <td>0.858555</td>\n",
       "      <td>0.004331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.562905</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.010007</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>{'n_estimators': 50, 'min_samples_split': 10, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.692326</td>\n",
       "      <td>0.694973</td>\n",
       "      <td>0.025375</td>\n",
       "      <td>3</td>\n",
       "      <td>0.842610</td>\n",
       "      <td>0.847819</td>\n",
       "      <td>0.835143</td>\n",
       "      <td>0.853307</td>\n",
       "      <td>0.844720</td>\n",
       "      <td>0.006699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.051858</td>\n",
       "      <td>0.003696</td>\n",
       "      <td>0.004620</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>25</td>\n",
       "      <td>{'n_estimators': 10, 'min_samples_split': 2, '...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.671702</td>\n",
       "      <td>0.673322</td>\n",
       "      <td>0.025693</td>\n",
       "      <td>4</td>\n",
       "      <td>0.792505</td>\n",
       "      <td>0.768648</td>\n",
       "      <td>0.773263</td>\n",
       "      <td>0.790013</td>\n",
       "      <td>0.781107</td>\n",
       "      <td>0.010320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "2       0.240231      0.003902         0.012484        0.001115   \n",
       "0       0.576629      0.008529         0.010501        0.000495   \n",
       "3       0.562905      0.007968         0.010007        0.000714   \n",
       "1       0.051858      0.003696         0.004620        0.000807   \n",
       "\n",
       "  param_n_estimators param_min_samples_split param_min_samples_leaf  \\\n",
       "2                 50                       5                      2   \n",
       "0                 50                       5                      4   \n",
       "3                 50                      10                      4   \n",
       "1                 10                       2                      4   \n",
       "\n",
       "  param_max_features param_max_depth  \\\n",
       "2               sqrt              20   \n",
       "0               auto              10   \n",
       "3               auto              10   \n",
       "1               sqrt              25   \n",
       "\n",
       "                                              params  ...  split3_test_score  \\\n",
       "2  {'n_estimators': 50, 'min_samples_split': 5, '...  ...           0.704604   \n",
       "0  {'n_estimators': 50, 'min_samples_split': 5, '...  ...           0.694651   \n",
       "3  {'n_estimators': 50, 'min_samples_split': 10, ...  ...           0.692326   \n",
       "1  {'n_estimators': 10, 'min_samples_split': 2, '...  ...           0.671702   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "2         0.702167        0.035749                1            0.866996   \n",
       "0         0.701833        0.020514                2            0.853191   \n",
       "3         0.694973        0.025375                3            0.842610   \n",
       "1         0.673322        0.025693                4            0.792505   \n",
       "\n",
       "   split1_train_score  split2_train_score  split3_train_score  \\\n",
       "2            0.861138            0.863663            0.864847   \n",
       "0            0.863521            0.855475            0.862032   \n",
       "3            0.847819            0.835143            0.853307   \n",
       "1            0.768648            0.773263            0.790013   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "2          0.864161         0.002115  \n",
       "0          0.858555         0.004331  \n",
       "3          0.844720         0.006699  \n",
       "1          0.781107         0.010320  \n",
       "\n",
       "[4 rows x 23 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View results in order of performance\n",
    "random_df = pd.DataFrame(rf_random.cv_results_).sort_values('mean_test_score', ascending = False)\n",
    "random_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit best estimator to data\n",
    "rf_model = rf_random.best_estimator_\n",
    "rf_model.fit(x_train,y_train)\n",
    "y_pred = rf_model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58812477.66885509  6566516.23483217 55534352.73071918 ...\n",
      " 74251068.32273747 81059611.44950631 15466008.73756455]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions with random forest\n",
    "test_pred = rf_model.predict(x_test)\n",
    "print(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second submission RMSLE: 2.74767"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boosted decision tree\n",
    "ada = AdaBoostRegressor(n_estimators=100, base_estimator=DecisionTreeRegressor(max_depth=10), learning_rate=1e-3, random_state=42)\n",
    "\n",
    "ada.fit(x_train,y_train)\n",
    "\n",
    "y_pred = ada.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7922983.2         4208492.96226415 19919542.66666667 ...\n",
      " 49309719.53488372 26260552.25       10904523.60344828]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions with AdaBoosted regressor\n",
    "test_pred = ada.predict(x_test)\n",
    "print(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third submission RMSLE: 2.62765"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parameter grid for DecisionTreeRegressor\n",
    "param = { 'max_depth': [5, 10, 15, 20, 25, None],\n",
    " 'max_features': ['auto', 'sqrt', 'log2'],\n",
    " 'min_samples_leaf': [1, 2, 3, 4, 5, 6],\n",
    " 'min_samples_split': [2, 5, 10],\n",
    " 'min_weight_fraction_leaf': [0.0, 0.1, 0.25, 0.5, 0.75]}\n",
    "\n",
    "# Instantiate stratified k-fold\n",
    "cv = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jessl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    2.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=0, shuffle=True),\n",
       "                   error_score=nan,\n",
       "                   estimator=DecisionTreeRegressor(ccp_alpha=0.0,\n",
       "                                                   criterion='mse',\n",
       "                                                   max_depth=None,\n",
       "                                                   max_features=None,\n",
       "                                                   max_leaf_nodes=None,\n",
       "                                                   min_impurity_decrease=0.0,\n",
       "                                                   min_impurity_split=None,\n",
       "                                                   min_samples_leaf=1,\n",
       "                                                   min_samples_split=2,\n",
       "                                                   min_weight_fraction_leaf=0.0,\n",
       "                                                   presort='deprecated',\n",
       "                                                   ra...\n",
       "                                                   splitter='best'),\n",
       "                   iid='deprecated', n_iter=4, n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [5, 10, 15, 20, 25, None],\n",
       "                                        'max_features': ['auto', 'sqrt',\n",
       "                                                         'log2'],\n",
       "                                        'min_samples_leaf': [1, 2, 3, 4, 5, 6],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'min_weight_fraction_leaf': [0.0, 0.1,\n",
       "                                                                     0.25, 0.5,\n",
       "                                                                     0.75]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=True, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision tree regressor identified with RandomizedSearchCV\n",
    "tree = DecisionTreeRegressor()\n",
    "tree_random = RandomizedSearchCV(estimator = tree, param_distributions = param, n_iter = 4, cv = cv, verbose=2, random_state=42, n_jobs = -1, return_train_score = True)\n",
    "\n",
    "tree_random.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_min_weight_fraction_leaf</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.041405</td>\n",
       "      <td>0.004681</td>\n",
       "      <td>0.002914</td>\n",
       "      <td>0.001225</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>auto</td>\n",
       "      <td>20</td>\n",
       "      <td>{'min_weight_fraction_leaf': 0.0, 'min_samples...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.512178</td>\n",
       "      <td>0.134074</td>\n",
       "      <td>1</td>\n",
       "      <td>0.873170</td>\n",
       "      <td>0.882681</td>\n",
       "      <td>0.850041</td>\n",
       "      <td>0.885674</td>\n",
       "      <td>0.872761</td>\n",
       "      <td>0.872865</td>\n",
       "      <td>0.012502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.022818</td>\n",
       "      <td>0.013069</td>\n",
       "      <td>0.002594</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>auto</td>\n",
       "      <td>25</td>\n",
       "      <td>{'min_weight_fraction_leaf': 0.1, 'min_samples...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.392091</td>\n",
       "      <td>0.029035</td>\n",
       "      <td>2</td>\n",
       "      <td>0.398781</td>\n",
       "      <td>0.414742</td>\n",
       "      <td>0.413401</td>\n",
       "      <td>0.406383</td>\n",
       "      <td>0.412944</td>\n",
       "      <td>0.409250</td>\n",
       "      <td>0.005981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008385</td>\n",
       "      <td>0.001850</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>None</td>\n",
       "      <td>{'min_weight_fraction_leaf': 0.75, 'min_sample...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006596</td>\n",
       "      <td>0.001376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>log2</td>\n",
       "      <td>25</td>\n",
       "      <td>{'min_weight_fraction_leaf': 0.75, 'min_sample...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "2       0.041405      0.004681         0.002914        0.001225   \n",
       "0       0.022818      0.013069         0.002594        0.001353   \n",
       "1       0.008385      0.001850         0.000000        0.000000   \n",
       "3       0.006596      0.001376         0.000000        0.000000   \n",
       "\n",
       "  param_min_weight_fraction_leaf param_min_samples_split  \\\n",
       "2                              0                       5   \n",
       "0                            0.1                       2   \n",
       "1                           0.75                       2   \n",
       "3                           0.75                       2   \n",
       "\n",
       "  param_min_samples_leaf param_max_features param_max_depth  \\\n",
       "2                      4               auto              20   \n",
       "0                      4               auto              25   \n",
       "1                      2               sqrt            None   \n",
       "3                      3               log2              25   \n",
       "\n",
       "                                              params  ...  mean_test_score  \\\n",
       "2  {'min_weight_fraction_leaf': 0.0, 'min_samples...  ...         0.512178   \n",
       "0  {'min_weight_fraction_leaf': 0.1, 'min_samples...  ...         0.392091   \n",
       "1  {'min_weight_fraction_leaf': 0.75, 'min_sample...  ...              NaN   \n",
       "3  {'min_weight_fraction_leaf': 0.75, 'min_sample...  ...              NaN   \n",
       "\n",
       "   std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "2        0.134074                1            0.873170            0.882681   \n",
       "0        0.029035                2            0.398781            0.414742   \n",
       "1             NaN                3                 NaN                 NaN   \n",
       "3             NaN                4                 NaN                 NaN   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "2            0.850041            0.885674            0.872761   \n",
       "0            0.413401            0.406383            0.412944   \n",
       "1                 NaN                 NaN                 NaN   \n",
       "3                 NaN                 NaN                 NaN   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "2          0.872865         0.012502  \n",
       "0          0.409250         0.005981  \n",
       "1               NaN              NaN  \n",
       "3               NaN              NaN  \n",
       "\n",
       "[4 rows x 25 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore model options\n",
    "tree_df = pd.DataFrame(tree_random.cv_results_).sort_values('mean_test_score', ascending = False)\n",
    "tree_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model for use with boosted regressor\n",
    "tree_model = tree_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parameter grid for AdaBoostRegressor cross validation\n",
    "param = {'learning_rate': [0.001, 0.01, 0.05, 0.1, 0.3, 0.5, 1],\n",
    "         'base_estimator': [tree_model],\n",
    "         'n_estimators': [5, 10, 15, 20, 25, 50, 75, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jessl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    5.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=0, shuffle=True),\n",
       "                   error_score=nan,\n",
       "                   estimator=AdaBoostRegressor(base_estimator=None,\n",
       "                                               learning_rate=1.0, loss='linear',\n",
       "                                               n_estimators=50,\n",
       "                                               random_state=None),\n",
       "                   iid='deprecated', n_iter=4, n_jobs=-1,\n",
       "                   param_distributions={'base_estimator': [DecisionTreeRegressor(ccp_alpha=0.0,\n",
       "                                                                                 criterion='mse',\n",
       "                                                                                 max_depth=20,\n",
       "                                                                                 m...\n",
       "                                                                                 min_impurity_decrease=0.0,\n",
       "                                                                                 min_impurity_split=None,\n",
       "                                                                                 min_samples_leaf=4,\n",
       "                                                                                 min_samples_split=5,\n",
       "                                                                                 min_weight_fraction_leaf=0.0,\n",
       "                                                                                 presort='deprecated',\n",
       "                                                                                 random_state=None,\n",
       "                                                                                 splitter='best')],\n",
       "                                        'learning_rate': [0.001, 0.01, 0.05,\n",
       "                                                          0.1, 0.3, 0.5, 1],\n",
       "                                        'n_estimators': [5, 10, 15, 20, 25, 50,\n",
       "                                                         75, 100]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=True, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AdaBoostRegressor with RandomizedSearchCV\n",
    "ada = AdaBoostRegressor()\n",
    "\n",
    "ada_random = RandomizedSearchCV(estimator = ada, param_distributions = param, n_iter = 4, cv = cv, verbose=2, random_state=42, n_jobs = -1, return_train_score = True)\n",
    "\n",
    "ada_random.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_base_estimator</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.439661</td>\n",
       "      <td>0.153710</td>\n",
       "      <td>0.015388</td>\n",
       "      <td>0.002683</td>\n",
       "      <td>50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>DecisionTreeRegressor(ccp_alpha=0.0, criterion...</td>\n",
       "      <td>{'n_estimators': 50, 'learning_rate': 0.01, 'b...</td>\n",
       "      <td>0.751805</td>\n",
       "      <td>0.594714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697225</td>\n",
       "      <td>0.065673</td>\n",
       "      <td>1</td>\n",
       "      <td>0.941779</td>\n",
       "      <td>0.945766</td>\n",
       "      <td>0.937978</td>\n",
       "      <td>0.944119</td>\n",
       "      <td>0.942193</td>\n",
       "      <td>0.942367</td>\n",
       "      <td>0.002618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.635464</td>\n",
       "      <td>0.039560</td>\n",
       "      <td>0.020188</td>\n",
       "      <td>0.003544</td>\n",
       "      <td>50</td>\n",
       "      <td>0.001</td>\n",
       "      <td>DecisionTreeRegressor(ccp_alpha=0.0, criterion...</td>\n",
       "      <td>{'n_estimators': 50, 'learning_rate': 0.001, '...</td>\n",
       "      <td>0.755870</td>\n",
       "      <td>0.585920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.691530</td>\n",
       "      <td>0.064880</td>\n",
       "      <td>2</td>\n",
       "      <td>0.924742</td>\n",
       "      <td>0.939566</td>\n",
       "      <td>0.925808</td>\n",
       "      <td>0.930670</td>\n",
       "      <td>0.924800</td>\n",
       "      <td>0.929117</td>\n",
       "      <td>0.005663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.328052</td>\n",
       "      <td>0.033055</td>\n",
       "      <td>0.005602</td>\n",
       "      <td>0.001344</td>\n",
       "      <td>10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>DecisionTreeRegressor(ccp_alpha=0.0, criterion...</td>\n",
       "      <td>{'n_estimators': 10, 'learning_rate': 0.3, 'ba...</td>\n",
       "      <td>0.723569</td>\n",
       "      <td>0.490548</td>\n",
       "      <td>...</td>\n",
       "      <td>0.654603</td>\n",
       "      <td>0.089443</td>\n",
       "      <td>3</td>\n",
       "      <td>0.961746</td>\n",
       "      <td>0.967265</td>\n",
       "      <td>0.958569</td>\n",
       "      <td>0.966002</td>\n",
       "      <td>0.966616</td>\n",
       "      <td>0.964039</td>\n",
       "      <td>0.003349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.165956</td>\n",
       "      <td>0.010435</td>\n",
       "      <td>0.004587</td>\n",
       "      <td>0.001352</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>DecisionTreeRegressor(ccp_alpha=0.0, criterion...</td>\n",
       "      <td>{'n_estimators': 5, 'learning_rate': 0.001, 'b...</td>\n",
       "      <td>0.669025</td>\n",
       "      <td>0.438716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.598032</td>\n",
       "      <td>0.091372</td>\n",
       "      <td>4</td>\n",
       "      <td>0.889534</td>\n",
       "      <td>0.896253</td>\n",
       "      <td>0.900682</td>\n",
       "      <td>0.892827</td>\n",
       "      <td>0.872321</td>\n",
       "      <td>0.890323</td>\n",
       "      <td>0.009731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "3       1.439661      0.153710         0.015388        0.002683   \n",
       "1       1.635464      0.039560         0.020188        0.003544   \n",
       "2       0.328052      0.033055         0.005602        0.001344   \n",
       "0       0.165956      0.010435         0.004587        0.001352   \n",
       "\n",
       "  param_n_estimators param_learning_rate  \\\n",
       "3                 50                0.01   \n",
       "1                 50               0.001   \n",
       "2                 10                 0.3   \n",
       "0                  5               0.001   \n",
       "\n",
       "                                param_base_estimator  \\\n",
       "3  DecisionTreeRegressor(ccp_alpha=0.0, criterion...   \n",
       "1  DecisionTreeRegressor(ccp_alpha=0.0, criterion...   \n",
       "2  DecisionTreeRegressor(ccp_alpha=0.0, criterion...   \n",
       "0  DecisionTreeRegressor(ccp_alpha=0.0, criterion...   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "3  {'n_estimators': 50, 'learning_rate': 0.01, 'b...           0.751805   \n",
       "1  {'n_estimators': 50, 'learning_rate': 0.001, '...           0.755870   \n",
       "2  {'n_estimators': 10, 'learning_rate': 0.3, 'ba...           0.723569   \n",
       "0  {'n_estimators': 5, 'learning_rate': 0.001, 'b...           0.669025   \n",
       "\n",
       "   split1_test_score  ...  mean_test_score  std_test_score  rank_test_score  \\\n",
       "3           0.594714  ...         0.697225        0.065673                1   \n",
       "1           0.585920  ...         0.691530        0.064880                2   \n",
       "2           0.490548  ...         0.654603        0.089443                3   \n",
       "0           0.438716  ...         0.598032        0.091372                4   \n",
       "\n",
       "   split0_train_score  split1_train_score  split2_train_score  \\\n",
       "3            0.941779            0.945766            0.937978   \n",
       "1            0.924742            0.939566            0.925808   \n",
       "2            0.961746            0.967265            0.958569   \n",
       "0            0.889534            0.896253            0.900682   \n",
       "\n",
       "   split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
       "3            0.944119            0.942193          0.942367         0.002618  \n",
       "1            0.930670            0.924800          0.929117         0.005663  \n",
       "2            0.966002            0.966616          0.964039         0.003349  \n",
       "0            0.892827            0.872321          0.890323         0.009731  \n",
       "\n",
       "[4 rows x 23 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View results in order of performance\n",
    "ada_df = pd.DataFrame(ada_random.cv_results_).sort_values('mean_test_score', ascending = False)\n",
    "ada_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit best boosted model\n",
    "ada_model = ada_random.best_estimator_\n",
    "ada_model.fit(x_train,y_train)\n",
    "\n",
    "y_pred = ada_model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8257385521892944"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RMSLE performance on training data with boosted model\n",
    "np.sqrt(mean_squared_log_error(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17180747.4         2959067.66666667 10042097.75       ...\n",
      " 27867209.25        7574496.           925690.2       ]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions with boosted model\n",
    "test_pred = ada_model.predict(x_test)\n",
    "print(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fourth submission RMSLE: 2.49591\n",
    "# Baseline 1 RMSLE met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try logistic regression\n",
    "log = LogisticRegression()\n",
    "log.fit(x_train,y_train)\n",
    "test_pred = log.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                    metric_params=None, n_jobs=None, n_neighbors=6, p=2,\n",
       "                    weights='uniform')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try K-Neighbors Regression\n",
    "model_knn = KNeighborsRegressor(n_neighbors=6)\n",
    "model_knn.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model_knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try XGBoost regression\n",
    "xg_reg = xg_reg = xgb.XGBRegressor(colsample_bytree = 0.3, learning_rate = 0.001,\n",
    "                max_depth = 3, alpha = 10, n_estimators = 15000)\n",
    "xg_reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = xg_reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>3001</td>\n",
       "      <td>1.718075e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3001</th>\n",
       "      <td>3002</td>\n",
       "      <td>2.959068e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3002</th>\n",
       "      <td>3003</td>\n",
       "      <td>1.004210e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3003</th>\n",
       "      <td>3004</td>\n",
       "      <td>1.037189e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3004</th>\n",
       "      <td>3005</td>\n",
       "      <td>4.679764e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id       revenue\n",
       "3000  3001  1.718075e+07\n",
       "3001  3002  2.959068e+06\n",
       "3002  3003  1.004210e+07\n",
       "3003  3004  1.037189e+07\n",
       "3004  3005  4.679764e+06"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This chunk of code is run for every modeling attempt to create a valid Kaggle submission for RMLSE testing\n",
    "test[\"revenue\"] = test_pred\n",
    "result = test[[\"id\",\"revenue\"]]\n",
    "result.to_csv(\"adatree_clean.csv\", index=False)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following the development of the AdaBoost decision tree, some additional feature engineering was done to reach the second baseline of 2.0\n",
    "# Creating the franchise variable - RMSLE: 2.48561\n",
    "# Modifying the production variable - RMSLE: 2.46957\n",
    "# Creating the tagline dummy - RMSLE: 2.53704\n",
    "# Creating the production dummy - RMSLE: 2.49776\n",
    "# Creating the homepage dummy - RMSLE: 2.54564\n",
    "# Add additional CV values for AdaBoost tuning - RMSLE: 2.48674\n",
    "# Add additional CV values for DecisionTreeRegressor tuning - RMSLE: 2.50032\n",
    "# Create budget and keyword variable with K-Neighbors regression - RMSLE: 2.51089\n",
    "# Create variable for runtime and try normalization - RMSLE: 2.35785\n",
    "# Creating date variables - RMSLE: 2.31145\n",
    "# Try with cross-validated logistic regression - RMSLE: 3.97993\n",
    "# More runtime feature engineering - RMSLE: 2.30573\n",
    "# Removing ID variable - RMSLE: 2.28516\n",
    "# Removing keyword dummy and creating separate actor variables - RMSLE: 2.27979\n",
    "# Title change variable - RMSLE: 2.29110\n",
    "# Modifying budget information - RMSLE: 2.28542\n",
    "# Keyword mining - RMSLE: 2.27859"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
